"""Multi-Agent Debate System â€” inspired by Grok 4.2 architecture.

Implements a four-agent debate workflow:
  Captain (åè°ƒè€…) â†’ Harper/Benjamin/Lucas (å¹¶è¡Œ) â†’ Debate (è¾©è®º) â†’ Captain (åˆæˆ)

Agents:
  - Captain:   ä»»åŠ¡åˆ†è§£ã€ç­–ç•¥åˆ¶å®šã€å†²çªè§£å†³ã€æœ€ç»ˆåˆæˆ
  - Harper:    ç ”ç©¶ & äº‹å®ä¸“å®¶ï¼Œæ‹¥æœ‰æœç´¢/æŠ“å–å·¥å…·
  - Benjamin:  é€»è¾‘/åˆ†æä¸“å®¶ï¼Œæ¨ç†éªŒè¯ã€ä¸€è‡´æ€§æ£€æŸ¥
  - Lucas:     åˆ›æ„ & è´¨ç–‘è€…ï¼Œåå‘æ€è€ƒã€åè§æ£€æµ‹
"""

import json
import time
from typing import Any, AsyncGenerator, Dict, List, Literal, Optional, TypedDict

from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import END, START, StateGraph
from loguru import logger

from app.core.config import settings
from app.services.ai.audit import AuditLogger
from app.services.ai.model_provider import get_chat_model


# ---------------------------------------------------------------------------
# Shared State
# ---------------------------------------------------------------------------

class DebateState(TypedDict):
    """Shared state flowing through the multi-agent debate graph."""
    query: str
    user_id: str
    custom_system_prompt: Optional[str]
    # Captain decomposition
    complexity: str          # "simple" | "moderate" | "complex"
    sub_tasks: List[str]
    active_agents: List[str]
    # Agent outputs (round 1)
    harper_output: str
    benjamin_output: str
    lucas_output: str
    # Debate outputs (round 2)
    harper_rebuttal: str
    benjamin_rebuttal: str
    lucas_rebuttal: str
    # Final
    final_report: str
    confidence: str
    sources: List[Dict[str, str]]
    # Streaming
    status_updates: List[str]


# ---------------------------------------------------------------------------
# Agent Prompts
# ---------------------------------------------------------------------------

CAPTAIN_DECOMPOSE_PROMPT = """ä½ æ˜¯ç ”ç©¶å›¢é˜Ÿçš„é˜Ÿé•¿(Captain)ã€‚ä½ çš„èŒè´£æ˜¯åˆ†æç”¨æˆ·é—®é¢˜çš„å¤æ‚åº¦ï¼Œå¹¶åˆ†è§£ä¸ºå­ä»»åŠ¡ã€‚

è¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼Œè¾“å‡ºä¸¥æ ¼çš„JSONï¼ˆä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š
{{
  "complexity": "simple|moderate|complex",
  "sub_tasks": ["å­ä»»åŠ¡1", "å­ä»»åŠ¡2", ...],
  "active_agents": ["harper", "benjamin", "lucas"],
  "strategy": "ç®€è¦è¯´æ˜ç ”ç©¶ç­–ç•¥"
}}

è§„åˆ™ï¼š
- simple: åªéœ€Harperæœç´¢å³å¯å›ç­”ï¼Œactive_agents=["harper"]
- moderate: éœ€è¦æœç´¢+é€»è¾‘éªŒè¯ï¼Œactive_agents=["harper","benjamin"]
- complex: éœ€è¦å…¨éƒ¨ä»£ç†å‚ä¸è¾©è®ºï¼Œactive_agents=["harper","benjamin","lucas"]
- sub_tasks: 2-5ä¸ªå…·ä½“å¯æ‰§è¡Œçš„å­ä»»åŠ¡

ç”¨æˆ·é—®é¢˜: {query}"""

HARPER_PROMPT = """ä½ æ˜¯Harperï¼Œç ”ç©¶å›¢é˜Ÿçš„äº‹å®ä¸ä¿¡æ¯ä¸“å®¶ã€‚

ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
- åŸºäºæœç´¢ç»“æœæä¾›å‡†ç¡®ã€æœ€æ–°çš„äº‹å®ä¿¡æ¯
- æ•´ç†å…³é”®æ•°æ®ç‚¹ï¼Œæ ‡æ³¨æ¥æº
- åŒºåˆ†å·²è¯å®çš„äº‹å®å’Œæœªç»éªŒè¯çš„è¯´æ³•
- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œæ˜ç¡®æŒ‡å‡º

ä½ çš„é£æ ¼ï¼šä¸¥è°¨ã€æ•°æ®é©±åŠ¨ã€æ³¨é‡æ¥æºå¯ä¿¡åº¦ã€‚

{custom_prompt}

ç”¨æˆ·é—®é¢˜: {query}
å­ä»»åŠ¡: {sub_tasks}

æœç´¢ç»“æœ:
{search_data}

è¯·æä¾›ä½ çš„ç ”ç©¶å‘ç°ï¼ˆç”¨ä¸­æ–‡ï¼‰:"""

BENJAMIN_PROMPT = """ä½ æ˜¯Benjaminï¼Œç ”ç©¶å›¢é˜Ÿçš„é€»è¾‘ä¸åˆ†æä¸“å®¶ã€‚

ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
- å¯¹é—®é¢˜è¿›è¡Œä¸¥è°¨çš„é€»è¾‘åˆ†æ
- æ£€éªŒæ¨ç†é“¾çš„æ¯ä¸€æ­¥æ˜¯å¦æˆç«‹
- è¯†åˆ«å› æœå…³ç³»ã€ç›¸å…³æ€§ä¸å·§åˆçš„åŒºåˆ«
- æŒ‡å‡ºè®ºè¯ä¸­çš„é€»è¾‘æ¼æ´æˆ–éšå«å‡è®¾
- å¦‚æœæ¶‰åŠæ•°æ®ï¼ŒéªŒè¯æ•°å€¼çš„åˆç†æ€§

ä½ çš„é£æ ¼ï¼šä¸¥å¯†ã€ç»“æ„åŒ–ã€ä¸æ”¾è¿‡ä»»ä½•é€»è¾‘ç¼ºé™·ã€‚

{custom_prompt}

ç”¨æˆ·é—®é¢˜: {query}
å­ä»»åŠ¡: {sub_tasks}

Harperçš„ç ”ç©¶å‘ç°:
{harper_output}

è¯·æä¾›ä½ çš„é€»è¾‘åˆ†æï¼ˆç”¨ä¸­æ–‡ï¼‰:"""

LUCAS_PROMPT = """ä½ æ˜¯Lucasï¼Œç ”ç©¶å›¢é˜Ÿçš„åˆ›æ„æ€è€ƒè€…ä¸è´¨ç–‘è€…ã€‚

ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
- æŒ‘æˆ˜ä¸»æµè§‚ç‚¹ï¼Œæå‡ºåå‘è®ºè¯
- æ£€æµ‹æ½œåœ¨çš„è®¤çŸ¥åè§ï¼ˆç¡®è®¤åè¯¯ã€å¹¸å­˜è€…åå·®ç­‰ï¼‰
- æä¾›è¢«å¿½è§†çš„æ›¿ä»£è§†è§’æˆ–è§£è¯»
- è¯„ä¼°ç»“è®ºçš„å…¨é¢æ€§ï¼ŒæŒ‡å‡ºç›²ç‚¹
- è®©æœ€ç»ˆè¾“å‡ºæ›´å…·å¯è¯»æ€§å’Œå¹³è¡¡æ€§

ä½ çš„é£æ ¼ï¼šå‘æ•£ã€æ‰¹åˆ¤æ€§ã€å¯Œæœ‰æ´å¯ŸåŠ›ï¼Œä½†ä¸ä¸ºåå¯¹è€Œåå¯¹ã€‚

{custom_prompt}

ç”¨æˆ·é—®é¢˜: {query}
å­ä»»åŠ¡: {sub_tasks}

Harperçš„ç ”ç©¶å‘ç°:
{harper_output}

Benjaminçš„é€»è¾‘åˆ†æ:
{benjamin_output}

è¯·æä¾›ä½ çš„æ‰¹åˆ¤æ€§è§†è§’ï¼ˆç”¨ä¸­æ–‡ï¼‰:"""

DEBATE_PROMPT = """ä½ æ˜¯{agent_name}ã€‚åœ¨çœ‹åˆ°å…¶ä»–ä»£ç†çš„åˆ†æåï¼Œè¯·è¿›è¡Œäº¤å‰æ ¡éªŒã€‚

ä½ ä¹‹å‰çš„åˆ†æ:
{own_output}

å…¶ä»–ä»£ç†çš„è§‚ç‚¹:
{other_outputs}

è¯·ç®€è¦å›åº”ï¼š
1. ä½ åŒæ„æˆ–ä¿®æ­£å“ªäº›è§‚ç‚¹ï¼Ÿ
2. ä½ ä»ç„¶åšæŒçš„æ ¸å¿ƒè®ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ
3. æœ‰ä»€ä¹ˆæ–°çš„è¡¥å……ï¼Ÿ

ä¿æŒç®€æ´ï¼ˆ200å­—ä»¥å†…ï¼‰:"""

CAPTAIN_SYNTHESIZE_PROMPT = """ä½ æ˜¯ç ”ç©¶å›¢é˜Ÿçš„é˜Ÿé•¿(Captain)ã€‚ç°åœ¨éœ€è¦å°†å›¢é˜Ÿçš„ç ”ç©¶æˆæœåˆæˆä¸ºæœ€ç»ˆæŠ¥å‘Šã€‚

åŸå§‹é—®é¢˜: {query}

== Harperï¼ˆç ”ç©¶ä¸“å®¶ï¼‰çš„å‘ç° ==
{harper_output}
{harper_rebuttal}

== Benjaminï¼ˆé€»è¾‘ä¸“å®¶ï¼‰çš„åˆ†æ ==
{benjamin_output}
{benjamin_rebuttal}

== Lucasï¼ˆåˆ›æ„è´¨ç–‘è€…ï¼‰çš„è§†è§’ ==
{lucas_output}
{lucas_rebuttal}

è¯·åˆæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Šï¼Œè¦æ±‚ï¼š
1. å¼€å¤´ç»™å‡º2-3å¥è¯çš„æ ¸å¿ƒç»“è®º
2. æŒ‰ä¸»é¢˜åˆ†æ®µï¼Œæ•´åˆä¸‰ä½ä¸“å®¶çš„æœ€ä½³è§‚ç‚¹
3. å¯¹æœ‰äº‰è®®çš„ç‚¹ï¼Œå‘ˆç°ä¸åŒè§†è§’å¹¶ç»™å‡ºä½ çš„åˆ¤æ–­
4. å…³é”®ä¿¡æ¯æ ‡æ³¨æ¥æº [æ¥æº](URL)
5. ç»“å°¾ç»™å‡ºç½®ä¿¡åº¦è¯„ä¼°ï¼ˆé«˜/ä¸­/ä½ï¼‰å’Œç†ç”±
6. å¦‚æœLucasæŒ‡å‡ºäº†æœ‰æ•ˆçš„ç›²ç‚¹ï¼Œå¿…é¡»åœ¨æŠ¥å‘Šä¸­ä½“ç°

{custom_prompt}

è¯·è¾“å‡ºæœ€ç»ˆæŠ¥å‘Šï¼ˆç”¨ä¸­æ–‡ï¼‰:"""


# ---------------------------------------------------------------------------
# Multi-Agent Debate Engine
# ---------------------------------------------------------------------------

class MultiAgentDebate:
    """Four-agent debate system inspired by Grok 4.2 architecture."""

    def __init__(self):
        self.audit = AuditLogger()

    def _build_graph(self, user_id: str) -> Any:
        model = get_chat_model()
        if model is None:
            return None

        async def _llm(system: str, user: str) -> str:
            """Helper: single LLM call with retry."""
            import asyncio
            for attempt in range(3):
                try:
                    resp = await asyncio.wait_for(
                        model.ainvoke([
                            SystemMessage(content=system),
                            HumanMessage(content=user),
                        ]),
                        timeout=90,
                    )
                    return resp.content or ""
                except Exception as e:
                    logger.warning(f"LLM call attempt {attempt+1} failed: {e}")
                    if attempt < 2:
                        await asyncio.sleep(2)
            return "(LLMè°ƒç”¨å¤±è´¥ï¼Œè·³è¿‡æ­¤æ­¥éª¤)"

        # ---- Node: captain_decompose ----
        async def captain_decompose(state: DebateState) -> dict:
            prompt = CAPTAIN_DECOMPOSE_PROMPT.format(query=state["query"])
            raw = await _llm("ä½ æ˜¯ç ”ç©¶å›¢é˜Ÿçš„é˜Ÿé•¿ã€‚", prompt)

            # Parse JSON
            try:
                start, end = raw.find("{"), raw.rfind("}")
                data = json.loads(raw[start:end + 1]) if start >= 0 else {}
            except Exception:
                data = {}

            complexity = data.get("complexity", "complex")
            sub_tasks = data.get("sub_tasks", [state["query"]])
            active = data.get("active_agents", ["harper", "benjamin", "lucas"])

            return {
                "complexity": complexity,
                "sub_tasks": sub_tasks,
                "active_agents": active,
                "status_updates": [
                    f"[ğŸ¯ Captain: å¤æ‚åº¦={complexity}, æ¿€æ´»ä»£ç†={','.join(active)}]",
                    f"[ğŸ“‹ å­ä»»åŠ¡: {'; '.join(sub_tasks[:3])}]",
                ],
            }

        # ---- Node: harper_research ----
        async def harper_research(state: DebateState) -> dict:
            if "harper" not in state["active_agents"]:
                return {"harper_output": "(Harperæœªæ¿€æ´»)", "status_updates": []}

            import asyncio

            search_data_parts = []
            external_urls = []

            async def _safe(coro, label, timeout_s=15):
                try:
                    return await asyncio.wait_for(coro, timeout=timeout_s)
                except Exception as e:
                    logger.warning(f"Harper {label} failed: {e}")
                    return None

            try:
                from app.services.ai.tools.search_tools import create_search_tools
                search_tools = create_search_tools(user_id)
                search_user = search_tools[0]
                web_search_tool = search_tools[2]

                for task in state["sub_tasks"][:2]:
                    es_raw = await _safe(search_user.ainvoke({"query": task, "limit": 3}), f"ES:{task[:20]}")
                    if es_raw:
                        es_data = json.loads(es_raw) if isinstance(es_raw, str) else es_raw
                        for r in es_data.get("results", []):
                            search_data_parts.append(f"[å†…éƒ¨] {r.get('title', '')} - {r.get('url', '')}: {r.get('description', '')[:100]}")

                    web_raw = await _safe(web_search_tool.ainvoke({"query": task, "max_results": 5}), f"Web:{task[:20]}")
                    if web_raw:
                        web_data = json.loads(web_raw) if isinstance(web_raw, str) else web_raw
                        for r in web_data.get("results", []):
                            search_data_parts.append(f"[å¤–éƒ¨] {r.get('title', '')} - {r.get('url', '')}: {r.get('description', '')[:100]}")
                            if r.get("url"):
                                external_urls.append({"title": r.get("title", ""), "url": r["url"]})
            except Exception as e:
                logger.warning(f"Harper search init failed: {e}")

            search_data = "\n".join(search_data_parts) or "(æ— æœç´¢ç»“æœ)"

            # Deep read: use light mode (skip Phase 2 LLM), parallel, pick best URLs
            deep_read_parts = []
            if external_urls:
                try:
                    from app.services.ai.agents.deep_research_agent import _scrape_light

                    # Simple relevance: prefer URLs whose title contains query keywords
                    query_chars = set(state["query"])
                    scored = sorted(external_urls, key=lambda u: sum(1 for c in query_chars if c in u["title"]), reverse=True)
                    top_urls = [u["url"] for u in scored[:2]]

                    tasks = [_scrape_light(url, timeout_s=60) for url in top_urls]
                    results = await asyncio.gather(*tasks, return_exceptions=True)

                    for url, result in zip(top_urls, results):
                        if isinstance(result, Exception) or not result:
                            continue
                        content = result.get("content", "")
                        if content:
                            deep_read_parts.append(
                                f"=== {result.get('title', url)} ===\n{content[:3000]}"
                            )
                except Exception as e:
                    logger.warning(f"Harper deep read failed: {e}")

            full_search_data = search_data
            if deep_read_parts:
                full_search_data += "\n\n--- ç½‘é¡µè¯¦ç»†å†…å®¹ ---\n" + "\n\n".join(deep_read_parts)

            custom = state.get("custom_system_prompt") or ""

            prompt = HARPER_PROMPT.format(
                query=state["query"],
                sub_tasks="; ".join(state["sub_tasks"]),
                search_data=full_search_data,
                custom_prompt=custom,
            )
            output = await _llm("ä½ æ˜¯Harperï¼Œç ”ç©¶å›¢é˜Ÿçš„äº‹å®ä¸ä¿¡æ¯ä¸“å®¶ã€‚", prompt)

            return {
                "harper_output": output,
                "status_updates": [
                    f"[Harper: æœé›†äº† {len(search_data_parts)} æ¡ä¿¡æ¯]",
                    *(
                        [f"[Harper: æ·±åº¦é˜…è¯»äº† {len(deep_read_parts)} ä¸ªç½‘é¡µ (light mode)]"]
                        if deep_read_parts else []
                    ),
                ],
            }

        # ---- Node: benjamin_analyze ----
        async def benjamin_analyze(state: DebateState) -> dict:
            if "benjamin" not in state["active_agents"]:
                return {"benjamin_output": "(Benjaminæœªæ¿€æ´»)", "status_updates": []}

            custom = state.get("custom_system_prompt") or ""
            prompt = BENJAMIN_PROMPT.format(
                query=state["query"],
                sub_tasks="; ".join(state["sub_tasks"]),
                harper_output=state["harper_output"],
                custom_prompt=custom,
            )
            output = await _llm("ä½ æ˜¯Benjaminï¼Œç ”ç©¶å›¢é˜Ÿçš„é€»è¾‘ä¸åˆ†æä¸“å®¶ã€‚", prompt)

            return {
                "benjamin_output": output,
                "status_updates": ["[ğŸ§  Benjamin: é€»è¾‘åˆ†æå®Œæˆ]"],
            }

        # ---- Node: lucas_challenge ----
        async def lucas_challenge(state: DebateState) -> dict:
            if "lucas" not in state["active_agents"]:
                return {"lucas_output": "(Lucasæœªæ¿€æ´»)", "status_updates": []}

            custom = state.get("custom_system_prompt") or ""
            prompt = LUCAS_PROMPT.format(
                query=state["query"],
                sub_tasks="; ".join(state["sub_tasks"]),
                harper_output=state["harper_output"],
                benjamin_output=state["benjamin_output"],
                custom_prompt=custom,
            )
            output = await _llm("ä½ æ˜¯Lucasï¼Œç ”ç©¶å›¢é˜Ÿçš„åˆ›æ„æ€è€ƒè€…ä¸è´¨ç–‘è€…ã€‚", prompt)

            return {
                "lucas_output": output,
                "status_updates": ["[ğŸ’¡ Lucas: æ‰¹åˆ¤æ€§è§†è§’å®Œæˆ]"],
            }

        # ---- Node: debate_round ----
        async def debate_round(state: DebateState) -> dict:
            """Cross-verification: each agent reviews others' work."""
            rebuttals = {}

            agents_config = [
                ("harper", state["harper_output"], f"Benjamin: {state['benjamin_output']}\nLucas: {state['lucas_output']}"),
                ("benjamin", state["benjamin_output"], f"Harper: {state['harper_output']}\nLucas: {state['lucas_output']}"),
                ("lucas", state["lucas_output"], f"Harper: {state['harper_output']}\nBenjamin: {state['benjamin_output']}"),
            ]

            for agent_name, own, others in agents_config:
                if agent_name not in state["active_agents"]:
                    rebuttals[f"{agent_name}_rebuttal"] = ""
                    continue

                prompt = DEBATE_PROMPT.format(
                    agent_name=agent_name.capitalize(),
                    own_output=own,
                    other_outputs=others,
                )
                rebuttal = await _llm(f"ä½ æ˜¯{agent_name.capitalize()}ï¼Œæ­£åœ¨è¿›è¡Œå›¢é˜Ÿè¾©è®ºã€‚", prompt)
                rebuttals[f"{agent_name}_rebuttal"] = rebuttal

            return {
                **rebuttals,
                "status_updates": ["[âš”ï¸ è¾©è®ºè½®: ä»£ç†é—´äº¤å‰æ ¡éªŒå®Œæˆ]"],
            }

        # ---- Node: captain_synthesize ----
        async def captain_synthesize(state: DebateState) -> dict:
            custom = state.get("custom_system_prompt") or ""
            prompt = CAPTAIN_SYNTHESIZE_PROMPT.format(
                query=state["query"],
                harper_output=state["harper_output"],
                harper_rebuttal=state.get("harper_rebuttal", ""),
                benjamin_output=state["benjamin_output"],
                benjamin_rebuttal=state.get("benjamin_rebuttal", ""),
                lucas_output=state["lucas_output"],
                lucas_rebuttal=state.get("lucas_rebuttal", ""),
                custom_prompt=custom,
            )
            report = await _llm("ä½ æ˜¯ç ”ç©¶å›¢é˜Ÿçš„é˜Ÿé•¿ï¼Œè´Ÿè´£æœ€ç»ˆåˆæˆã€‚", prompt)

            return {
                "final_report": report,
                "status_updates": ["[âœ… Captain: æœ€ç»ˆæŠ¥å‘Šåˆæˆå®Œæˆ]"],
            }

        # ---- Routing ----
        def should_debate(state: DebateState) -> Literal["debate_round", "captain_synthesize"]:
            if state["complexity"] == "complex":
                return "debate_round"
            return "captain_synthesize"

        # ---- Build Graph ----
        builder = StateGraph(DebateState)

        builder.add_node("captain_decompose", captain_decompose)
        builder.add_node("harper_research", harper_research)
        builder.add_node("benjamin_analyze", benjamin_analyze)
        builder.add_node("lucas_challenge", lucas_challenge)
        builder.add_node("debate_round", debate_round)
        builder.add_node("captain_synthesize", captain_synthesize)

        # Flow: captain â†’ harper â†’ benjamin â†’ lucas â†’ (debate?) â†’ synthesize
        builder.add_edge(START, "captain_decompose")
        builder.add_edge("captain_decompose", "harper_research")
        builder.add_edge("harper_research", "benjamin_analyze")
        builder.add_edge("benjamin_analyze", "lucas_challenge")
        builder.add_conditional_edges("lucas_challenge", should_debate, ["debate_round", "captain_synthesize"])
        builder.add_edge("debate_round", "captain_synthesize")
        builder.add_edge("captain_synthesize", END)

        return builder.compile()

    async def run(
        self,
        query: str,
        user_id: str,
        system_prompt: Optional[str] = None,
    ) -> AsyncGenerator[str, None]:
        """Run the multi-agent debate and stream progress + final report."""
        t0 = time.monotonic()

        graph = self._build_graph(user_id)
        if graph is None:
            yield "AI åŠ©æ‰‹æš‚ä¸å¯ç”¨ï¼Œè¯·å…ˆé…ç½® OPENAI_API_KEYã€‚"
            return

        initial: DebateState = {
            "query": query,
            "user_id": user_id,
            "custom_system_prompt": system_prompt,
            "complexity": "complex",
            "sub_tasks": [],
            "active_agents": [],
            "harper_output": "",
            "benjamin_output": "",
            "lucas_output": "",
            "harper_rebuttal": "",
            "benjamin_rebuttal": "",
            "lucas_rebuttal": "",
            "final_report": "",
            "confidence": "",
            "sources": [],
            "status_updates": [],
        }

        try:
            async for event in graph.astream(initial, stream_mode="updates"):
                for node_name, node_output in event.items():
                    for status in node_output.get("status_updates", []):
                        yield status + "\n"

                    if node_name == "captain_synthesize" and node_output.get("final_report"):
                        yield "\n---\n\n"
                        yield node_output["final_report"]

            await self.audit.log(
                user_id=user_id,
                action="multi_agent_debate",
                input_summary=query[:200],
                output_summary="debate completed",
                model=settings.agent_model,
                latency_ms=int((time.monotonic() - t0) * 1000),
            )

        except Exception as e:
            logger.error(f"Multi-agent debate failed: {e}")
            yield f"\næŠ±æ­‰ï¼Œç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
            await self.audit.log(
                user_id=user_id,
                action="multi_agent_debate",
                input_summary=query[:200],
                model=settings.agent_model,
                latency_ms=int((time.monotonic() - t0) * 1000),
                error=str(e),
            )
